# Superstore Analysis
In this notebook we're going to analyse the superstore dataset from Kaggle. We have two(2) datasets Superstorestore_1 and Superstore_2 with 21 columns each. 
Superstore_1 dataset contains data for Row_Id 1-8001. Whilst Superstore_2 dataset contains data for Row_Id 8002-9994.

We're going to explore the dataset and find the following:

- Use LEAD windows funtion to create a new column 'SalesNext' that displays the sales value of the next row in the dataset.
* Use common SQL command and aggregate functions to show the monthly and daily sales average.
+ Analyze discounts on 2 consecutive day.
* Evaluate moving averages using the windows funtion.

# Display tables
The first and second line of code dispalys the data on superstore_1 and superstore_2 table.
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT *  \n",
    "FROM SUPERSTORE_1 \n"
  ]  
  },
 {
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT *  \n",
    "FROM SUPERSTORE_2 \n"
  ]  
  },
 
# Join tables
In the next step we will be joining the two tables using the SQL JOIN statement to give us one whole table for easy and accurate analysis. 
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * INTO Superstore \n",
    "FROM SUPERSTORE_1 \n",
    "UNION \n",
    "SELECT * FROM superstore_2;"
   ]
  },

# Create "salesnext" column

Next we want to create a new column named "salesnext" that displays the sales data of the next row to easily allow us compare the sales of the current and next row on the table using the LEAD function.
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f692a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT    \n",
    " Row_ID, Sales,\n",
    " LEAD (Sales, 1, 0)\n",
    " OVER(ORDER BY Row_ID) AS Sales_Next\n",
    "FROM Superstore;"
   ]
  },
  
# Create "salesprevious" column

Next we want to create a new column named "salesprevious" that displays the sales data of the previous row to easily allow us compare the sales of the current and previous row on the table using the LAG function.
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee00643",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    " Row_ID, Sales,\n",
    " LAG (Sales, 1, 0)\n",
    " OVER(ORDER BY Row_ID) AS Sales_Previous\n",
    "FROM Superstore;"
   ]
  },
 
# Rank data based on sales

This line of code displays data in descending order in the sales column. Based on the dataset, the highest sale made was 22638.48 USD whilst the least sale made was 0.44 USD.
 {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANK DATA BASED ON SALES \n",
    "\n",
    "SELECT\n",
    " Row_ID, Sales,\n",
    " RANK ()\n",
    " OVER(ORDER BY Sales DESC) AS Sales_Rank\n",
    "FROM Superstore;"
   ]   
  },
  
# Monthly and daily average sales.

Exploring further into the dataset, we asked what the daily and monthly averages were from the year 2014-2017. Based on our dataset, it turned out that the daily average sales was approximately 229.85 USD whilst the total monthly average was approximately 228.6 USD with the month of March having the highest average of approximately 294.54 USD and the Month of February having a monthly average of 199.17 USD. 
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8670e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAILY SALES AVERAGE\n",
    "\n",
    "SELECT \n",
    " AVG(Sales) AS Avgsales\n",
    "FROM SuperStore;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONTHLY SALES AVERAGE\n",
    "\n",
    "SELECT \n",
    "  AVG(Sales) AS Avgsales, DATENAME(MONTH, Order_Date) Month\n",
    "FROM SuperStore\n",
    "GROUP BY DATENAME(MONTH, Order_Date)\n",
    "ORDER BY Avgsales;"
   ]
  },
  
  # Discount on Two consecutive days.
  
  In the next line of code we analyzed the discount on two (2) consecutive days.
  
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCOUNT ON TWO CONSECUTIVE DAYS\n",
    "\n",
    "SELECT \n",
    "Order_date, Sales, Discount\n",
    "FROM Superstore\n",
    "WHERE Order_Date between '2014-01-18' AND '2014-01-19'"
   ]
  },
 
# Moving Average.
 
In the final step of our analysis, we evaluated the Moving Average discount and it turned out that there was a significant uptrend and downtrend from the year 2014-2017. 
 {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    " Order_date,TotalSales,  AVG(TotalDiscount)\n",
    " OVER(ORDER BY Order_Date ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) TwoDaysMovingAverage\n",
    "FROM (\n",
    " SELECT SUM(Sales) AS Totalsales, SUM(discount) AS Totaldiscount, Order_Date\n",
    "FROM SuperStore\n",
    "GROUP BY Order_Date) AS MovingAvg;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
